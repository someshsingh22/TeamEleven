{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled22.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "0u4qCvz-rQyO"
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import pandas as pd\n",
        "import json\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import LabelEncoder as LE\n",
        "import bisect\n",
        "import torch\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HM_adnLMrUkO"
      },
      "source": [
        "!cp -r drive/My\\ Drive/T11 ./T11"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9MIMdDzDVRTO",
        "outputId": "3399a8a7-7c3b-488b-ef56-b8bbbccae6fa"
      },
      "source": [
        "np.random.seed(22)\n",
        "torch.manual_seed(22)"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f1e3afeb720>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoqkKaEuR7Fz"
      },
      "source": [
        "with open('T11/batsmen.json', 'r') as f:\n",
        "  batsmen = json.load(f)\n",
        "with open('T11/bowlers.json', 'r') as f:\n",
        "  bowlers = json.load(f)\n",
        "batsmen = {k: [x for x in v if x[1][1]>=0] for k,v in batsmen.items()}\n",
        "batsmen = {k: sorted(v, key=lambda x : x[0]) for k,v in batsmen.items() if v}\n",
        "bowlers = {k: sorted(v, key=lambda x : x[0]) for k,v in bowlers.items() if v}"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a7-6sz9_6-UJ"
      },
      "source": [
        "def getBatScores(scores):\n",
        "  #runs, balls, boundaries, contribs, out\n",
        "  array = []\n",
        "  for score in scores:\n",
        "    date = score[0]\n",
        "    _, runs, balls, fours, sixes, _, contrib = score[1]\n",
        "    boundaries = fours + sixes * 1.5\n",
        "    array.append((date, np.array([runs, balls, boundaries, contrib])))\n",
        "  return array\n",
        "\n",
        "def getBowlScores(scores):\n",
        "  #overs, maidens, runs, wickets, contribs\n",
        "  array = []\n",
        "  for score in scores:\n",
        "    date = score[0]\n",
        "    overs, maidens, runs, wickets, _, contrib = score[1]\n",
        "    overs = int(overs) + (overs-int(overs))*10/6\n",
        "    array.append((date, np.array([overs, maidens, runs, wickets, contrib])))\n",
        "  return array\n",
        "\n",
        "batsmen_scores = {k:getBatScores(v) for k,v in batsmen.items()}\n",
        "bowlers_scores = {k:getBowlScores(v) for k,v in bowlers.items()}"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-uVzvAMKrB7C"
      },
      "source": [
        "_batsmen_scores = {k:{_v[0]: _v[1] for _v in v} for k,v in batsmen_scores.items()}\n",
        "_bowlers_scores = {k:{_v[0]: _v[1] for _v in v} for k,v in bowlers_scores.items()}"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nJ9G4LMlTM6"
      },
      "source": [
        "att = pd.read_csv('T11/attributes.csv')\n",
        "att['BatHand']=0+(att['Bats'].str.find('eft')>0)\n",
        "att['BowlHand']=0+(att['Bowls'].str.find('eft')>0)\n",
        "att['BowlType']=0+((att['Bowls'].str.find('ast')>0) | (att['Bowls'].str.find('edium')>0))"
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_LiWgE3Vid6S"
      },
      "source": [
        "def getBatStats(scores):\n",
        "  dates, scorelist = [score[0] for score in scores], [score[1] for score in scores]\n",
        "  scorelist = np.array(scorelist)\n",
        "  cumscores = np.cumsum(scorelist, axis=0)\n",
        "  innings = np.arange(1, cumscores.shape[0]+1)\n",
        "  average = cumscores[:, 0]/innings\n",
        "  sr = cumscores[:, 0]/(cumscores[:, 1]+1)\n",
        "  contrib = cumscores[:, 3]/innings\n",
        "  stats = np.array([innings, average, sr, contrib]).T\n",
        "  return [datetime.strptime(date, \"%Y-%m-%d\") for date in dates], stats\n",
        "\n",
        "def getBowlStats(scores):\n",
        "  dates, scorelist = [score[0] for score in scores], [score[1] for score in scores]\n",
        "  scorelist = np.array(scorelist)\n",
        "  cumscores = np.cumsum(scorelist, axis=0)\n",
        "  overs = cumscores[:, 0]\n",
        "  overs = overs.astype('int32')+10/6*(overs - overs.astype('int32'))\n",
        "  runs = cumscores[:, 2]\n",
        "  economy = runs/overs\n",
        "  wickets = cumscores[:, 3]\n",
        "  average = wickets/(runs+1)\n",
        "  sr = wickets/overs\n",
        "  contrib = cumscores[:, 4]/np.arange(1, cumscores.shape[0]+1)\n",
        "  stats = np.array([overs, average, economy, sr, contrib]).T\n",
        "  return [datetime.strptime(date, \"%Y-%m-%d\") for date in dates], stats"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jAUJtBaU_vuh"
      },
      "source": [
        "batsmen_stats = {key:getBatStats(getBatScores(v)) for key,v in batsmen.items()}\n",
        "bowlers_stats = {key:getBowlStats(getBowlScores(v)) for key,v in bowlers.items()}"
      ],
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_DyRxXpFdEI"
      },
      "source": [
        "with open('T11/scorecard.json', 'r') as f:\n",
        "  scorecards = json.load(f)\n",
        "position = dict()\n",
        "for code, match in scorecards.items():\n",
        "  for pos, batsmen in enumerate(match['BATTING1']):\n",
        "    if batsmen[0] in position:\n",
        "      position[batsmen[0]].append(pos+1)\n",
        "    else:\n",
        "      position[batsmen[0]]=[pos+1]\n",
        "  for pos, batsmen in enumerate(match['BATTING2']):\n",
        "    if batsmen[0] in position:\n",
        "      position[batsmen[0]].append(pos+1)\n",
        "    else:\n",
        "      position[batsmen[0]]=[pos+1]\n",
        "\n",
        "position = {int(k):max(set(v), key = v.count) for k,v in position.items()}\n",
        "for missing in set(att['Code']) - set(position.keys()):\n",
        "  position[missing]=0"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9mzgSue2pjA2"
      },
      "source": [
        "with open('T11/region.json','r') as f:\n",
        "  region = json.load(f)\n",
        "with open('T11/tmap.json','r') as f:\n",
        "  tmap = json.load(f)"
      ],
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYoWwjtdF_hh"
      },
      "source": [
        "matches = pd.read_csv('T11/matches.csv')\n",
        "att['BatPos']=att['Code'].apply(lambda x : position[x])\n",
        "matches['GroundCode']=matches['GroundCode'].apply(lambda x : region[str(x)])\n",
        "matches=matches[pd.to_datetime(matches['Date'], format='%Y-%m-%d')>\"1990-01-01\"]\n",
        "df_cards = pd.DataFrame(scorecards).transpose()\n",
        "df_cards = df_cards[df_cards.index.astype(int).isin(matches['MatchCode'])]\n",
        "matches = matches[matches['MatchCode'].isin(df_cards.index.astype(int))]"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "bLvvm1AuqaDP",
        "outputId": "a497e5d7-dd64-4119-fc7f-48b69213596c"
      },
      "source": [
        "att=pd.get_dummies(att, columns=['BatPos'])\n",
        "le = {\n",
        "    'GC' : LE(),\n",
        "    'Team' : LE(),\n",
        "    'Venue' : LE(),\n",
        "    }\n",
        "le['Team'].fit((matches['Team_1'].tolist())+(matches['Team_2'].tolist()))\n",
        "matches['Team_1']=le['Team'].transform(matches['Team_1'])\n",
        "matches['Team_2']=le['Team'].transform(matches['Team_2'])\n",
        "matches['Venue']=le['Venue'].fit_transform(matches['Venue'])\n",
        "matches['GroundCode']=le['GC'].fit_transform(matches['GroundCode'])\n",
        "matches"
      ],
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Date</th>\n",
              "      <th>Team_1</th>\n",
              "      <th>Team_2</th>\n",
              "      <th>Venue</th>\n",
              "      <th>MatchCode</th>\n",
              "      <th>GroundCode</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2015-03-04</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>3773</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2012-08-25</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3437</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2019-06-01</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4306</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2014-03-01</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3623</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2016-09-25</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>3936</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3645</th>\n",
              "      <td>1993-11-21</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>915</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3646</th>\n",
              "      <td>1996-02-16</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>1115</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3647</th>\n",
              "      <td>1999-09-02</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>1575</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3648</th>\n",
              "      <td>2000-07-11</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>1703</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3649</th>\n",
              "      <td>2000-07-16</td>\n",
              "      <td>13</td>\n",
              "      <td>14</td>\n",
              "      <td>2</td>\n",
              "      <td>1706</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3086 rows Ã— 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            Date  Team_1  Team_2  Venue  MatchCode  GroundCode\n",
              "0     2015-03-04       0       1      0       3773           0\n",
              "1     2012-08-25       0       1      2       3437          12\n",
              "2     2019-06-01       0       1      2       4306           2\n",
              "3     2014-03-01       0       2      0       3623           1\n",
              "4     2016-09-25       0       2      0       3936           1\n",
              "...          ...     ...     ...    ...        ...         ...\n",
              "3645  1993-11-21      13      14      2        915           3\n",
              "3646  1996-02-16      13      14      2       1115           3\n",
              "3647  1999-09-02      13      14      2       1575          13\n",
              "3648  2000-07-11      13      14      2       1703           2\n",
              "3649  2000-07-16      13      14      2       1706           2\n",
              "\n",
              "[3086 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lieZ9_4ppy6S"
      },
      "source": [
        "patts = att[['BatHand', 'BowlHand', 'BowlType', 'BatPos_0', 'BatPos_1', 'BatPos_2', 'BatPos_3', 'BatPos_4', 'BatPos_5', 'BatPos_6', 'BatPos_7', 'BatPos_8', 'BatPos_9', 'BatPos_10']].values\n",
        "pcodes = att['Code'].tolist()\n",
        "attdict = dict()\n",
        "for i,pc in enumerate(pcodes):\n",
        "  attdict[pc]=patts[i]"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlPb9chkv1H5"
      },
      "source": [
        "df_cards['MatchCode']=df_cards.index.astype(int)\n",
        "matches=matches.sort_values(by='MatchCode')\n",
        "df_cards=df_cards.sort_values(by='MatchCode')\n",
        "df_cards.reset_index(drop=True, inplace=True)\n",
        "matches.reset_index(drop=True, inplace=True)\n",
        "df_cards['BAT2']=le['Team'].transform(df_cards['ORDER'].apply(lambda x : tmap[x[1]]))\n",
        "df_cards['BAT1']=le['Team'].transform(df_cards['ORDER'].apply(lambda x : tmap[x[0]]))\n",
        "df_cards['RUN1']=df_cards['SCORES'].apply(lambda x : x[0])\n",
        "df_cards['RUN2']=df_cards['SCORES'].apply(lambda x : x[1])\n",
        "df_cards['TOSS']=le['Team'].transform(df_cards['TOSS'].apply(lambda x : tmap[x]))\n",
        "df = pd.merge(matches, df_cards)\n",
        "df['PLAYERS1']=df['BATTING1'].apply(lambda x : [y[0] for y in x])\n",
        "df['PLAYERS2']=df['BATTING2'].apply(lambda x : [y[0] for y in x])"
      ],
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJHgEmwINnci"
      },
      "source": [
        "_BAT1, _BAT2, _BOW1, _BOW2 = df['PLAYERS1'].tolist(), df['PLAYERS2'].tolist(), [[_x[0] for _x in x] for x in df['BOWLING1'].tolist()], [[_x[0] for _x in x] for x in df['BOWLING2'].tolist()]\n",
        "for i in range(len(_BAT1)):\n",
        "  try:\n",
        "    _BAT1[i].append(list(set(_BOW2[i])-set(_BAT1[i]))[0])\n",
        "    _BAT2[i].append(list(set(_BOW1[i])-set(_BAT2[i]))[0])\n",
        "  except:\n",
        "    pass\n",
        "df['PLAYERS1'], df['PLAYERS2'] = _BAT1, _BAT2\n",
        "df=df[['Date', 'Team_1', 'Team_2', 'Venue', 'GroundCode', 'TOSS', 'BAT1', 'BAT2', 'RUN1', 'RUN2', 'PLAYERS1', 'PLAYERS2']]"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SXpq35bNZ4g6"
      },
      "source": [
        "df=df[df['PLAYERS1'].apply(lambda x : len(x)==11) & df['PLAYERS2'].apply(lambda x : len(x)==11)]\n",
        "df.reset_index(drop=True, inplace=True)"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PuiDfVY43FGG"
      },
      "source": [
        "Team_1, Team_2, BAT1, BAT2, BOWL1, BOWL2= [], [], [], [], [], []\n",
        "for t1,t2,b1,b2 in zip(df['Team_1'].tolist(), df['Team_2'].tolist(), df['BAT1'].tolist(), df['BAT2'].tolist()):\n",
        "  if b1==t1:\n",
        "    Team_1.append(t1)\n",
        "    Team_2.append(t2)\n",
        "  else:\n",
        "    Team_1.append(t2)\n",
        "    Team_2.append(t1)\n",
        "df['Team_1']=Team_1\n",
        "df['Team_2']=Team_2\n",
        "df.drop(['BAT1', 'BAT2', 'Venue'],axis=1, inplace=True)"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hkMQFNEqnZKq"
      },
      "source": [
        "def getStats(code, date):\n",
        "  _date = datetime.strptime(date, \"%Y-%m-%d\")\n",
        "  if code in batsmen_stats:\n",
        "    i = bisect.bisect_left(batsmen_stats[code][0], _date)-1\n",
        "    if i == -1:\n",
        "      bat = np.zeros(4)\n",
        "    else:\n",
        "      bat = batsmen_stats[code][1][i]\n",
        "  else:\n",
        "    bat = np.zeros(4)\n",
        "\n",
        "  if code in bowlers_stats:\n",
        "    i = bisect.bisect_left(bowlers_stats[code][0], _date)-1\n",
        "    if i == -1:\n",
        "      bowl = np.zeros(5)\n",
        "    else:\n",
        "      bowl = bowlers_stats[code][1][i]\n",
        "  else:\n",
        "    bowl = np.zeros(5)\n",
        "  if int(code) in attdict:\n",
        "    patt = attdict[int(code)]\n",
        "  else:\n",
        "    patt = np.zeros(14)\n",
        "  stats = np.concatenate([bat, bowl, patt])\n",
        "  return stats\n",
        "\n",
        "def getScores(code, date):\n",
        "  if code in _batsmen_scores and date in _batsmen_scores[code]:\n",
        "    bat = _batsmen_scores[code][date]\n",
        "  else:\n",
        "    bat = np.zeros(4)\n",
        "  if code in _bowlers_scores and date in _bowlers_scores[code]:\n",
        "    bowl = _bowlers_scores[code][date]\n",
        "  else:\n",
        "    bowl = np.zeros(5)\n",
        "  return np.concatenate([bat, bowl])"
      ],
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P13eCQTeQKxQ"
      },
      "source": [
        "P1, P2, Dates = df['PLAYERS1'].tolist(), df['PLAYERS2'].tolist(), df['Date'].tolist()\n",
        "PStats1, PStats2 = [[getStats(p, date) for p in team] for team,date in zip(P1,Dates)], [[getStats(p, date) for p in team] for team,date in zip(P2,Dates)]\n",
        "PScores1, PScores2 = [[getScores(p, date) for p in team] for team,date in zip(P1,Dates)], [[getScores(p, date) for p in team] for team,date in zip(P2,Dates)]"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hIdPORIID4ra",
        "outputId": "966b6847-b7ad-4599-979a-58ce96c53482"
      },
      "source": [
        "def getNRR(matchcode):\n",
        "  card = scorecards[matchcode]\n",
        "  run1, run2 = card['SCORES']\n",
        "  overs = sum([int(b[1]) + 10/6*(b[1]-int(b[1])) for b in card['BOWLING2']])\n",
        "  allout = not (len(card['BATTING2'][-1][1])<2 or ('not' in card['BATTING2'][-1][1]))\n",
        "  if allout:\n",
        "    overs=50\n",
        "  return abs((run1/50) - (run2/overs))\n",
        "df['NRR']=matches['MatchCode'].apply(lambda x : getNRR(str(x)))\n",
        "df['TEAM1WIN']=0\n",
        "df['TEAM1WIN'][df['RUN1']>df['RUN2']]=1\n",
        "df_0=df[df['TEAM1WIN']==0]\n",
        "df_1=df[df['TEAM1WIN']==1]\n",
        "df_0['NRR']=-df_0['NRR']\n",
        "df=(df_0.append(df_1)).sort_index()"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  # This is added back by InteractiveShellApp.init_path()\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1-qYa5CeAcE"
      },
      "source": [
        "nPStats1, nPStats2, nPScores1, nPScores2 = np.array(PStats1),  np.array(PStats2),  np.array(PScores1),  np.array(PScores2)"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADs_e8DRvmyz"
      },
      "source": [
        "StatMaxes = np.max(np.concatenate([nPStats1, nPStats2]), axis=(0,1))\n",
        "dfStats_N1 = nPStats1/StatMaxes\n",
        "dfStats_N2 = nPStats2/StatMaxes\n",
        "ScoreMaxes = np.max(np.concatenate([nPScores1, nPScores2]), axis=(0,1))\n",
        "dfScores_N1 = nPScores1/ScoreMaxes\n",
        "dfScores_N2 = nPScores2/ScoreMaxes\n",
        "NRRMax = np.max(df['NRR'])\n",
        "df['NRR']=df['NRR']/NRRMax"
      ],
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rf8pekkKJWrg"
      },
      "source": [
        "nnPStats1 = np.concatenate([dfStats_N1, dfStats_N2],axis=0)\n",
        "nnPStats2 = np.concatenate([dfStats_N2, dfStats_N1],axis=0)\n",
        "nnPScores1 = np.concatenate([dfScores_N1, dfScores_N2],axis=0)\n",
        "nnPScores2 = np.concatenate([dfScores_N2, dfScores_N1],axis=0)\n",
        "_NRR = np.concatenate([df['NRR'].values, -df['NRR'].values])"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tdDjoH121-37"
      },
      "source": [
        "train_idx, test_idx = train_test_split(np.arange(2*len(df)), test_size=0.1)"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wb6BcZKOXICv"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch import optim\n",
        "class AE(nn.Module):\n",
        "    def __init__(self, input_shape=12, output_shape=1, hidden=16, dropout=0.2):\n",
        "        super(AE, self).__init__()\n",
        "        self.hidden = hidden\n",
        "        self.input_shape = input_shape\n",
        "        self.output_shape = output_shape\n",
        "        self.noise = GaussianNoise(sigma=0.1)\n",
        "        self.player_encoder = nn.Sequential(\n",
        "            nn.Linear(input_shape, hidden),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden, hidden),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        self.score_regressor = nn.Sequential(\n",
        "            nn.Linear(hidden, 9),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.Linear(hidden, input_shape)\n",
        "        )\n",
        "\n",
        "        self.team_encoder = nn.Sequential(\n",
        "            nn.Linear(11*hidden, hidden*4),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "        self.nrr_regressor = nn.Sequential(\n",
        "            nn.Linear(hidden*8, hidden*2),\n",
        "            nn.Tanh(),\n",
        "            nn.Dropout(dropout),\n",
        "            nn.Linear(hidden*2, output_shape),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, x1, x2):\n",
        "        encoded1, decoded1, scores1 = [], [], []\n",
        "        encoded2, decoded2, scores2 = [], [], []\n",
        "        for i in range(11):\n",
        "          e1 = self.player_encoder(x1[:,i,:])\n",
        "          d1 = self.decoder(e1)\n",
        "          e2 = self.player_encoder(x2[:,i,:])\n",
        "          d2 = self.decoder(e2)\n",
        "          noise = (0.1**0.5)*torch.randn(e1.size())\n",
        "          e1, e2 = e1 + noise, e2 + noise\n",
        "          scores1.append(self.score_regressor(e1))\n",
        "          scores2.append(self.score_regressor(e2))\n",
        "          encoded1.append(e1)\n",
        "          decoded1.append(d1)\n",
        "          encoded2.append(e2)\n",
        "          decoded2.append(d2)\n",
        "        team1, team2 = self.team_encoder(torch.cat(tuple(encoded1), axis=1)), self.team_encoder(torch.cat(tuple(encoded2), axis=1))\n",
        "        out = self.nrr_regressor(torch.cat((team1, team2), axis=1))\n",
        "        decoded=torch.cat(tuple(decoded1 + decoded2), axis=1)\n",
        "        scores1=torch.cat(tuple(scores1),axis=1)\n",
        "        scores2=torch.cat(tuple(scores2),axis=1)\n",
        "        return decoded, out, scores1, scores2"
      ],
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MBsSMpjiPvj",
        "outputId": "2382234d-9150-4e1b-f2f4-15ec716ea930"
      },
      "source": [
        "model = AE(dropout=0.3)     \n",
        "criterion = nn.MSELoss()\n",
        "ED_Loss_train, NRR_Loss_train, Player_Loss_train = [], [], []\n",
        "ED_Loss_test, NRR_Loss_test, Player_Loss_test = [], [], []           \n",
        "optimizer = optim.RMSprop(model.parameters(), lr=3e-4, )\n",
        "epochs = 10000\n",
        "for epoch in range(1,epochs+1): \n",
        "  model.train()\n",
        "  inputs1 = torch.FloatTensor(nnPStats1[:,:,:12][train_idx])\n",
        "  inputs2 = torch.FloatTensor(nnPStats2[:,:,:12][train_idx])\n",
        "  outputs = torch.FloatTensor(_NRR[train_idx].reshape(-1,1))   \n",
        "  optimizer.zero_grad()\n",
        "  decoded, out, scores1, scores2 = model(inputs1, inputs2)\n",
        "  inp = (inputs1).view(train_idx.shape[0], -1), (inputs2).view(train_idx.shape[0], -1)\n",
        "  loss1 = criterion(decoded, torch.cat(inp, axis=1)) \n",
        "  loss2 = criterion(out, outputs)\n",
        "  loss3 = criterion(scores1, torch.FloatTensor(nnPScores1[train_idx]).view(train_idx.shape[0], -1))\n",
        "  loss4 = criterion(scores2, torch.FloatTensor(nnPScores2[train_idx]).view(train_idx.shape[0], -1))\n",
        "  loss = 1e-5*loss1 + 1*loss2 + 1e-3*(loss3 + loss4)\n",
        "  loss.backward()\n",
        "  ED_Loss_train.append(loss1.item())\n",
        "  NRR_Loss_train.append(loss2.item())\n",
        "  Player_Loss_train.append((loss3.item()+loss4.item())/2)\n",
        "  optimizer.step()\n",
        "  if epoch%100==0:\n",
        "    print(f\"Epoch {epoch}/{epochs}\")\n",
        "    print(\"Train Losses Decoder: %0.3f NRR: %0.3f Player Performance %0.3f\" % (loss1.item(), loss2.item(), (loss3.item()+loss4.item())/2))\n",
        "    model.eval()\n",
        "    inputs1 = torch.FloatTensor(nnPStats1[:,:,:12][test_idx])\n",
        "    inputs2 = torch.FloatTensor(nnPStats2[:,:,:12][test_idx])\n",
        "    outputs = torch.FloatTensor(_NRR[test_idx].reshape(-1,1))\n",
        "    decoded, out, scores1, scores2 = model(inputs1, inputs2)\n",
        "    inp = (inputs1).view(test_idx.shape[0], -1), (inputs2).view(test_idx.shape[0], -1)\n",
        "    loss1 = criterion(decoded, torch.cat(inp, axis=1)) \n",
        "    loss2 = criterion(out, outputs)\n",
        "    loss3 = criterion(scores1, torch.FloatTensor(nnPScores1[test_idx]).view(test_idx.shape[0], -1))\n",
        "    loss4 = criterion(scores2, torch.FloatTensor(nnPScores2[test_idx]).view(test_idx.shape[0], -1))\n",
        "    ED_Loss_test.append(loss1.item())\n",
        "    print(\"Validation Losses Decoder: %0.3f NRR: %0.3f Player Performance: %0.3f\" % (loss1.item(), loss2.item(), (loss3.item()+loss4.item())/2))\n",
        "    NRR_Loss_test.append(loss2.item())\n",
        "    out, outputs = out.detach().numpy(), outputs.detach().numpy()\n",
        "    Player_Loss_test.append((loss3.item()+loss4.item())/2)\n",
        "    acc=100*np.sum((out*outputs)>0)/out.shape[0]\n",
        "    print(\"Val Accuracy: %0.3f\" % acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/10000\n",
            "Train Losses Decoder: 0.126 NRR: 0.020 Player Performance 0.086\n",
            "Validation Losses Decoder: 0.116 NRR: 0.013 Player Performance: 0.079\n",
            "Val Accuracy: 48.013\n",
            "Epoch 20/10000\n",
            "Train Losses Decoder: 0.119 NRR: 0.018 Player Performance 0.079\n",
            "Validation Losses Decoder: 0.110 NRR: 0.012 Player Performance: 0.074\n",
            "Val Accuracy: 50.497\n",
            "Epoch 30/10000\n",
            "Train Losses Decoder: 0.114 NRR: 0.018 Player Performance 0.075\n",
            "Validation Losses Decoder: 0.106 NRR: 0.012 Player Performance: 0.070\n",
            "Val Accuracy: 51.325\n",
            "Epoch 40/10000\n",
            "Train Losses Decoder: 0.110 NRR: 0.017 Player Performance 0.072\n",
            "Validation Losses Decoder: 0.102 NRR: 0.012 Player Performance: 0.067\n",
            "Val Accuracy: 51.159\n",
            "Epoch 50/10000\n",
            "Train Losses Decoder: 0.107 NRR: 0.017 Player Performance 0.069\n",
            "Validation Losses Decoder: 0.099 NRR: 0.012 Player Performance: 0.064\n",
            "Val Accuracy: 50.828\n",
            "Epoch 60/10000\n",
            "Train Losses Decoder: 0.104 NRR: 0.016 Player Performance 0.066\n",
            "Validation Losses Decoder: 0.096 NRR: 0.012 Player Performance: 0.062\n",
            "Val Accuracy: 51.490\n",
            "Epoch 70/10000\n",
            "Train Losses Decoder: 0.102 NRR: 0.016 Player Performance 0.064\n",
            "Validation Losses Decoder: 0.094 NRR: 0.012 Player Performance: 0.060\n",
            "Val Accuracy: 50.828\n",
            "Epoch 80/10000\n",
            "Train Losses Decoder: 0.100 NRR: 0.016 Player Performance 0.062\n",
            "Validation Losses Decoder: 0.092 NRR: 0.012 Player Performance: 0.058\n",
            "Val Accuracy: 53.311\n",
            "Epoch 90/10000\n",
            "Train Losses Decoder: 0.098 NRR: 0.016 Player Performance 0.061\n",
            "Validation Losses Decoder: 0.090 NRR: 0.012 Player Performance: 0.057\n",
            "Val Accuracy: 47.020\n",
            "Epoch 100/10000\n",
            "Train Losses Decoder: 0.096 NRR: 0.016 Player Performance 0.059\n",
            "Validation Losses Decoder: 0.088 NRR: 0.012 Player Performance: 0.056\n",
            "Val Accuracy: 54.801\n",
            "Epoch 110/10000\n",
            "Train Losses Decoder: 0.094 NRR: 0.016 Player Performance 0.058\n",
            "Validation Losses Decoder: 0.087 NRR: 0.012 Player Performance: 0.054\n",
            "Val Accuracy: 48.344\n",
            "Epoch 120/10000\n",
            "Train Losses Decoder: 0.093 NRR: 0.015 Player Performance 0.056\n",
            "Validation Losses Decoder: 0.085 NRR: 0.012 Player Performance: 0.053\n",
            "Val Accuracy: 53.642\n",
            "Epoch 130/10000\n",
            "Train Losses Decoder: 0.091 NRR: 0.015 Player Performance 0.055\n",
            "Validation Losses Decoder: 0.084 NRR: 0.012 Player Performance: 0.052\n",
            "Val Accuracy: 52.483\n",
            "Epoch 140/10000\n",
            "Train Losses Decoder: 0.090 NRR: 0.015 Player Performance 0.054\n",
            "Validation Losses Decoder: 0.083 NRR: 0.012 Player Performance: 0.051\n",
            "Val Accuracy: 53.974\n",
            "Epoch 150/10000\n",
            "Train Losses Decoder: 0.089 NRR: 0.015 Player Performance 0.053\n",
            "Validation Losses Decoder: 0.082 NRR: 0.012 Player Performance: 0.050\n",
            "Val Accuracy: 52.483\n",
            "Epoch 160/10000\n",
            "Train Losses Decoder: 0.087 NRR: 0.015 Player Performance 0.052\n",
            "Validation Losses Decoder: 0.080 NRR: 0.012 Player Performance: 0.049\n",
            "Val Accuracy: 50.166\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPmIGYh_tMyv"
      },
      "source": [
        "sns.lineplot(x=np.arange(1,10001), y=ED_Loss_train)\n",
        "sns.lineplot(x=np.arange(1,10001,50), y=ED_Loss_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xW9pafktfYaK"
      },
      "source": [
        "sns.lineplot(x=np.arange(1,10001), y=NRR_Loss_train)\n",
        "sns.lineplot(x=np.arange(1,10001,50), y=NRR_Loss_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEL6-50ygD6g"
      },
      "source": [
        "sns.lineplot(x=np.arange(1,10001), y=Player_Loss_train)\n",
        "sns.lineplot(x=np.arange(1,10001,50), y=Player_Loss_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DMKhhyfgLXQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}